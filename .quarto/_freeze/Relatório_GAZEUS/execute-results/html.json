{
  "hash": "10a16fed23c5ff10370840339910ca54",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Teste Técnico\" # Título do relatório\nsubtitle: \"**Posição de Data Analyst Jr - Buraco Jogatina**\"\nauthor: \"Fernanda Kelly R. Silva\" # Autor(a)\nlang: pt \ndate: \"2024-03-24\" \ndate-format: short \ntoc: true \nformat: \n    html: \n      #css: [\"custom.css\"] \n      code-fold: false \n      code-tools: true  \n      theme: \n        light: cosmo\n        dark: superhero \n#title-block-banner: \"#874a9c\" \ncode-annotations: hover \nexecute:\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Tarefa 01: SQL\n\nUm sistema de pagamentos, registra as transações dos seus usuários em duas tabelas:\n\nUsers: Contém o registro de usuários do sistema. Os seus atributos são:\n\n-   id: Identificador único de usuário\n-   age (idade): em anos\n-   país de residência: país onde o usuários indicou que reside\n\nTransactions: Que contém o registro de todas as transações que os usuários realizam através do sistema.\n\n-   transaction_id: Identificador único da transação\n-   transaction_date: Data na qual a transação foi realizada. O tipo é timestamp, ou seja, é um tipo de data que contém o ano, mês, dia, hora, minuto e segundos.\n-   user_id: Identificador do usuário que realizou a transação (é uma chave externa à tabela users)\n-   transaction_state: Campo que indica o estado da transação que pode ser *INITIATED*, *SUCCESS*, *FRAUD* or *CANCELLED*.\n-   transaction_amount: Valor da transação em USD\n\nCom estes dados disponíveis, precisamos gerar queries SQL para responder às seguintes perguntas. **Para fins didáticos, criei esses bancos de dados para simular a resolução das questões.**\n\n### tabela_transactions\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(tabela_transactions)\n```\n\n::: {.cell-output-display}\n\n\n|user_id |transaction_date        |transaction_id |transaction_state | transaction_amount|data_curta |\n|:-------|:-----------------------|:--------------|:-----------------|------------------:|:----------|\n|1       |2024-03-12 15:08:49 UTC |255            |sucesso           |             119.65|2024-03-12 |\n|2       |2024-03-23 20:08:03 UTC |585            |INITIATED         |              22.63|2024-03-23 |\n|3       |2024-03-18 10:56:25 UTC |178            |CANCELLED         |             225.87|2024-03-18 |\n|4       |2024-03-12 08:21:32 UTC |887            |SUCCESS           |              16.58|2024-03-12 |\n|5       |2024-03-30 05:24:49 UTC |569            |FRAUD             |            1225.89|2024-03-30 |\n|6       |2024-03-21 12:32:51 UTC |789            |SUCCESS           |              59.90|2024-03-21 |\n|7       |2024-03-10 08:25:49 UTC |236            |FRAUD             |             256.98|2024-03-10 |\n|7       |2024-03-10 05:21:49 UTC |458            |FRAUD             |             986.69|2024-03-10 |\n|7       |2024-03-09 01:08:49 UTC |125            |FRAUD             |            1256.89|2024-03-09 |\n\n\n:::\n:::\n\n\n\n### tabela_user\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(tabela_user)\n```\n\n::: {.cell-output-display}\n\n\n|id |age |pais           |\n|:--|:---|:--------------|\n|1  |18  |Brasil         |\n|2  |29  |Estados Unidos |\n|3  |55  |África do Sul  |\n|4  |32  |Bolívia        |\n|5  |60  |Brasil         |\n|6  |42  |Brasil         |\n|7  |38  |África do Sul  |\n\n\n:::\n:::\n\n\n\nPara que a experiência do SQL seja real, vou conectar as bases com o SQLite.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dbplyr)\nlibrary(dplyr)\n\ncon <- DBI::dbConnect(RSQLite::SQLite(), \":memory:\")\ncopy_to(con, tabela_user)\ncopy_to(con, tabela_transactions)\n\ntabela_user <- tbl(con, \"tabela_user\")                 # <1>\ntabela_transactions <- tbl(con, \"tabela_transactions\") # <2>\n```\n:::\n\n\n\n1.  Conectando a base de dados {tabela_user} com o SQLite\n2.  Conectando a base de dados {tabela_transactions} com o SQLite\n\n::: panel-tabset\n# A\n\nQual é a idade média de usuários do sistema por país?\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: callout-tip\n# Resposta\n:::\n\n``` sql\n<SQL>\nSELECT `pais`, ROUND(AVG(`age`), 2) AS `media_idade`\nFROM `tabela_user`\nGROUP BY `pais`\n```\n\n# B\n\nQual é o país com a maior quantidade de dinheiro transacionado (considere só transações finalizadas com sucesso ou \"SUCCESS\")?\n\nComo vamos precisar do merge das duas tabelas, vou criar a **tabela_merge** sem algum filtro para facilitar as consultas e não alocar memória desnecessária.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntabela_merge <- tabela_transactions %>%\n                 dplyr::left_join(tabela_user, by = c(\"user_id\" = \"id\")) \n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n::: callout-tip\n# Resposta\n:::\n\n``` sql\n<SQL>\nSELECT\n  `user_id`,\n  `transaction_date`,\n  `transaction_id`,\n  `transaction_state`,\n  `transaction_amount`,\n  `data_curta`,\n  `age`,\n  `pais`\nFROM (\n  SELECT `q01`.*, RANK() OVER (ORDER BY `transaction_amount` DESC) AS `col01`\n  FROM (\n    SELECT `tabela_transactions`.*, `age`, `pais`\n    FROM `tabela_transactions`\n    LEFT JOIN `tabela_user`\n      ON (`tabela_transactions`.`user_id` = `tabela_user`.`id`)\n  ) AS `q01`\n  WHERE (`transaction_state` = 'SUCCESS' OR `transaction_state` = 'sucesso')\n) AS `q01`\nWHERE (`col01` <= 1)\n```\n\n# C\n\nQual é o país com maior taxa de fraude em porcentagem respeito ao número de transações totais no país?\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: callout-tip\n# Resposta\n:::\n\n``` sql\n<SQL>\nSELECT\n  `user_id`,\n  `transaction_date`,\n  `transaction_id`,\n  `transaction_state`,\n  `transaction_amount`,\n  `data_curta`,\n  `age`,\n  `pais`,\n  `taxa`\nFROM (\n  SELECT `q01`.*, RANK() OVER (ORDER BY `taxa` DESC) AS `col01`\n  FROM (\n    SELECT\n      `q01`.*,\n      `transaction_amount` / SUM(`transaction_amount`) OVER (PARTITION BY `transaction_state`) AS `taxa`\n    FROM (\n      SELECT `tabela_transactions`.*, `age`, `pais`\n      FROM `tabela_transactions`\n      LEFT JOIN `tabela_user`\n        ON (`tabela_transactions`.`user_id` = `tabela_user`.`id`)\n    ) AS `q01`\n  ) AS `q01`\n  WHERE (`transaction_state` = 'FRAUD')\n) AS `q01`\nWHERE (`col01` <= 1)\n```\n\n# D\n\nNa mesma linha da pergunta anterior, responda qual é a faixa de idade de usuários que mais cometem fraude (em percentagem). Separe as faixas etárias em: (\\<18 anos, 18-30 anos, 30 - 45 anos, 45 - 60 anos, 60 \\> anos) e considere que para responder essa pergunta, você deverá considerar o fato que um usuário pode ter executado várias transações, das quais poucas (ou muitas) podem ter sido fraude entre as demais.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: callout-tip\n# Resposta\n:::\n\n``` sql\n```\n\n# E\n\nImagine que a camada executiva da empresa dona do sistema, precisa criar um Dashboard para monitorar o estado das transações nos últimos 3 dias. Para isso você precisa criar uma query SQL que calcule o número e dinheiro das transações não finalizadas, número e dinheiro de transações finalizadas com sucesso (SUCCESS), o número e dinheiro de transações canceladas (CANCELLED), o número e dinheiro de fraudes (FRAUD), agrupado por país, nos 3 dias anteriores de quando o executivo da empresa consulte seu Dashboard.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: callout-tip\n# Resposta\n:::\n\n``` sql\n<SQL>\nSELECT\n  `q01`.*,\n  COUNT(*) OVER `win1` AS `n_transacoes`,\n  SUM(`transaction_amount`) OVER `win1` AS `dinheiro`\nFROM (\n  SELECT\n    `user_id`,\n    `transaction_date`,\n    `transaction_id`,\n    CASE WHEN (`transaction_state` = 'sucesso') THEN 'SUCCESS' WHEN NOT (`transaction_state` = 'sucesso') THEN `transaction_state` END AS `transaction_state`,\n    `transaction_amount`,\n    `data_curta`,\n    `age`,\n    `pais`,\n    `tres_n`\n  FROM (\n    SELECT\n      `q01`.*,\n      CASE WHEN ((DATE('now') - 1.0) = `data_curta`) THEN 1.0 WHEN NOT ((DATE('now') - 1.0) = `data_curta`) THEN (CASE WHEN ((DATE('now') - 2.0) = `data_curta`) THEN 1.0 WHEN NOT ((DATE('now') - 2.0) = `data_curta`) THEN (CASE WHEN ((DATE('now') - 2.0) = `data_curta`) THEN 1.0 WHEN NOT ((DATE('now') - 2.0) = `data_curta`) THEN 0.0 END) END) END AS `tres_n`\n    FROM (\n      SELECT `tabela_transactions`.*, `age`, `pais`\n      FROM `tabela_transactions`\n      LEFT JOIN `tabela_user`\n        ON (`tabela_transactions`.`user_id` = `tabela_user`.`id`)\n    ) AS `q01`\n  ) AS `q01`\n  WHERE (`tres_n` = 1.0)\n) AS `q01`\nWINDOW `win1` AS (PARTITION BY `pais`, `transaction_state`)\n```\n:::\n\n# Tarefa 02: Python\n\n\n\n::: {.cell}\n\n:::\n\n\n\nNuma tribo ancestral e muito desenvolvida, orientada principalmente por uma cultura lógica e matemática, os nativos estão interessados no estudo das linguagens de outras tribos e civilizações.\n\nDurante seus estudos, estes perceberam que as linguagens dessas outras civilizações são compostas por um conjunto de símbolos (letras do alfabeto) que são agrupados e combinados para representar conceitos (palavras). Assim mesmo, estes também sabem que cada civilização possui um alfabeto específico.\n\nNa tentativa da tribo de avançar nos seus estudos, estes desejam saber qual seria o número de palavras possíveis a serem criadas em função do tamanho da palavra e o conjunto de símbolos (alfabeto) da civilização em estudo, independentemente se essas \"palavras\" representam algum significado ou não.\n\n::: panel-tabset\n# A\n\nVocê, que compartilha os atributos da tribo enquanto as capacidades analíticas e lógicas, precisa ajudá-la escrevendo um algoritmo para fazer o cálculo descrito acima, considerando que tribo oferecerá para você o alfabeto da civilização e o tamanho da palavra/combinação. Seu algoritmo deveria ser capaz de calcular que o número total de palavras possíveis (independente se tem significado ou não) é de 16.\n\nOBS: NÃO PRECISA ESCREVER A LISTA DAS PALAVRAS, A TRIBO SÓ PRECISA DO NÚMERO!\n\n::: callout-tip\n# Resposta\n\nEsse é um claro problema de análise combinatória com reposição/reposição.\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom itertools import combinations_with_replacement,chain\n\n# Obtem todas as combinações de [1, 2, 3] e tamanho 2\ncomb_A = combinations_with_replacement([1, 2, 3], 2)\nprint(len(list(comb_A)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6\n```\n\n\n:::\n:::\n\n\n\n# B\n\nPara ajudar a tribo ainda mais! Você deverá modificar seu algoritmo (ou talvez escrever um novo) para fazer o mesmo cálculo, só que agora, as palavras não podem ter símbolos repetidos.\n\n::: callout-tip\n# Resposta\n\nEsse também é um claro problema de análise combinatória, mas, nesse caso, é um problema em que **não há reposição**.\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom itertools import combinations\n\n# Obtem todas as permutações de {@,d,2,b}  \ncomb_B = combinations([1, 2, 3], 2)\n\nprint(len(list(comb_B)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3\n```\n\n\n:::\n:::\n\n\n:::\n\n# Tarefa 03: Estatística e Machine Learning\n\n::: panel-tabset\n# 1\n\nDado um dataset das estaturas (em centímetros) de 13 indivíduos:\n\nDataset = {175, 166, 183, 193, 155, 177, 173, 171, 162, 185, 176, 161, 188}\n\nCalcule:\n\n-   a média\n-   a mediana\n-   20 percentil\n-   80 percentil\n-   desvio padrão\n\nConsiderando os dados, responda a que distribuição (paramétrica) os dados se aproximam.\n\n::: callout-tip\n# Resposta\n:::\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| vinte_percentil|     mean| median| oitenta_percentil| desvio_padrao|\n|---------------:|--------:|------:|-----------------:|-------------:|\n|           163.6| 174.2308|    175|             184.2|      11.25577|\n\n\n:::\n:::\n\n\n\nDe acordo com o gráfico abaixo, a distribuição da variável **altura** pode ser descrita por uma normal, mas para fins de decisão, deve-se munir de testes paramétricos ou não paramétricos. Veja que sua variabilidade indica que os valores observados tendem a estar distantes da média – ou seja, a distribuição é mais “espalhada”.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Relatório_GAZEUS_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(dataset$altura)\nqqline(dataset$altura, col=2)\n```\n\n::: {.cell-output-display}\n![](Relatório_GAZEUS_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n# 2\n\nCom suas próprias palavras, explique em que consiste o teorema central do limite, e se possível, mencione a sua importância no campo da inferência estatística.\n\n::: callout-tip\n# Resposta\n:::\n\nO Teorema do limite central (TLC) basicamente demonstra a **tendência** de aproximação das variáveis aleatórias com a distribuição normal, em que a aproximação da distribuição Normal melhora na medida que se fizesse a média do lançamento de mais dados. Esse comportamento pode ser visualizado na imagem abaixo. Na estatística, há provas que um n igual a 30 é suficientemente grande para que essa amostra seja descrita com uma distribuição normal e, por isso, é fácil encontrar análises clássicas com todos os pressupostos violados por seus pesquisadores devido a esta pressuposição do n igual a 30.\n\n![Teorema do Limite Central](img/img213.png){fig-align=\"center\" width=\"300\"}\n\n# 3\n\nSuponha que numa escola, 2 grupos diferentes de estudantes (Grupo A e Grupo B) fazem o mesmo teste de matemáticas. As pontuações para cada grupo são dados pelos seguintes datasets:\n\n-   Grupo A: {80, 85, 88, 90, 92, 75, 78}\n-   Grupo B: {75, 78, 82, 85, 87, 93, 99}\n\nElabore um teste de hipótese para determinar se existe uma diferença estatisticamente significativa entre a média das pontuações dos dois grupos com uma confiança de 95%.\n\n::: callout-tip\n# Resposta\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n**Antes de qualquer levantamento de hipótese, é bom analisar as medidas de tendência central de cada grupo e também graficamente** e, de acordo com a tabela abaixo, não há muitas evidências de que essa média entre os grupos seja diferente, mas é evidente que o **grupo B** tem uma variabilidade maior em relação as notas (desvio padrão = 8.363754).\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| vinte_percentil|     mean| median| oitenta_percentil| desvio_padrao|\n|---------------:|--------:|------:|-----------------:|-------------:|\n|           163.6| 174.2308|    175|             184.2|      11.25577|\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](Relatório_GAZEUS_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\nÉ importante ressaltar que a verificação dos pressupostos é de extrema relevância para que os insights e conclusões sejam verdadeiramente corretos. Neste casso, estamos **supondo ** que as duas amostras são independentes e, em caso de teste de médias, usaríamos o teste t independente que apresenta dois **pressupostos**:\n\n- **Normalidade da variável dependente de cada grupo**\n- **Homogeneidade de variâncias (ou seja, grupos com variâncias homogêneas)**\n\n### Normalidade\n\nPara verificar a normalidade dos dados, é recomendável utilizar o teste de **Shapiro WIlk** quando o número de amostra é menor que 50. A estatı́stica T (ou T ) é basicamente o quadrado de um coeficiente de correlação, onde o coeficiente de correlação de Pearson é calculado entre a estatı́stica ordenada X i na amostra e o escore ai , que representa o que a estatı́stica ordenada deveria parecer se a população é Normal. Portanto, as hipóteses levantadas são:\n\n$H_{0}$ : F(x) é função de distribuição normal;\n$H_{1}$ : F(x) não é função de distribuição normal;\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|grupo |variable | statistic|         p|\n|:-----|:--------|---------:|---------:|\n|A     |nota     | 0.9434822| 0.6702574|\n|B     |nota     | 0.9727151| 0.9172920|\n\n\n:::\n:::\n\n\n\n\nVeja que de acordo com o teste de Shapiro Wilk, ao nível de 95% de significância, **não rejeita-se a hipótese nula**, ou seja, a variável **notas** é descrita por uma distribuição normal.\n\n\n### Variância\n\nO segundo pressuposto pode ser avaliado pelo **teste de Levene**, em que as hipóteses são:\n\n$H_{0}$ : Os grupos apresentam variâncias homogêneas;\n$H_{1}$ : Os grupos não apresentam variâncias homogêneas;\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|      | Df|   F value|   Pr(>F)|\n|:-----|--:|---------:|--------:|\n|group |  1| 0.2060638| 0.657971|\n|      | 12|        NA|       NA|\n\n\n:::\n:::\n\n\n\nLogo, ao nível de 95% de significância, **não rejeitamos a hipótese nula**, ou seja, os grupos apresentam variâncias homogêneas e assim podemos seguir com o teste t independente.\n\nSeguindo os passos para elaboração de um teste de hipótese:\n\n1.  Enunciar as Hipóteses:\n\n- $H_{0}$ : Não há diferença média entre os grupos; \n- $H_{1}$ : Há diferença média entre os grupos;\n\n2. Fixar o nı́vel de significância $\\alpha$) do teste:\n\n**No nosso caso, o nível de significância será 95%.**\n\n- $\\alpha$ : Erro tipo I: Rejeitar $H_{0}$  quando é verdadeira.\n\n\n3. Escolha da Estatı́stica teste adequada:\n\nPara responder a essa pergunta, usaremos o teste-t independente. Note que queremos comparar as notas (variáveis numéricas) de dois grupos independentes de alunos (A x B).\n\n4. Obtenção dos valores crı́ticos e Obtenção da Estatı́stica calculada:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  nota by grupo\nt = -0.39353, df = 12, p-value = 0.7008\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -10.271845   7.128988\nsample estimates:\nmean in group A mean in group B \n       84.00000        85.57143 \n```\n\n\n:::\n:::\n\n\n\n6. Conclusão e tomada de decisão\n\nO teste resulta em um valor de t (no caso, t = -0.3935) e um valor de p (p-value) que é calculado com base nesse valor de t e nos graus de liberdade (df, do inglês degrees of freedom). Nesse caso, o valor de p é: 0.7008, um valor superior ao nível de significância 0.05. Como p > 0.05, não vamos rejeitar a $H_{0}$ e considerar que os dois grupos que apresentam notas, em média, não são estatisticamente diferentes. Veja que o IC 95% para a diferença entre médias inclui o zero: [-10.27; 7.12].\n\n\n# 4\n\nDetermine a hipótese nula (Ho) e hipótese alternativa (Ha) do seguinte cenário: Uma empresa afirma que o tempo médio dos seus produtos é menos de 4 dias. Você, conta com uma amostra dessas entregas para validar estadísticamente essa afirmação.\n\n::: callout-tip\n# Resposta\n:::\n\nNão é possível avaliar os pressupostos dessa amostra, mas considerando que esse tempo médio seja em dias (inteiros), o teste paramétrico sobre uma média populacional, a hipótese nula utilizada seria:\n\n\n- $H_{0}$ : $\\mu$ = 4;\n- $H_{1}$ : $\\mu$ $\\neq$ 4;\n\n\n# 5\n\nCalcule o coeficiente de correlação de pearson das variáveis \"Número de aparições Zendaya em filmes por ano\" e \"Número de pessoas afogadas em piscinas no Brasil ao ano\". Em base nos seus resultados, considera que a variável \"Número de aparições Zendaya em filmes por ano\" é um bom preditor do número de pessoas afogadas no Brasil? Justifique a sua resposta.\n\n::: callout-tip\n# Resposta\n:::\n\n# 6\n\nExplique a diferença entre amostragem estratificada e amostragem randômica ou aleatória. Discuta quais são as vantagens e desvantagens de cada uma e dê exemplos de casos onde uma abordagem é mais adequada que a outra.\n\n::: callout-tip\n# Resposta\n:::\n\n# 7\n\nSe você treina um modelo de Machine Learning (ou estadístico), como você identificaria se seu modelo tem uma alta variância (overfitting) ou um alto viés (bias, ou underfitting). Caso seu modelo apresenta alta variância, como você resolveria esse problema?\n\n::: callout-tip\n# Resposta\n:::\n\n# 8\n\nConsidere o seguinte modelo de regressão:\n\n-   Salário = 1200+ 500.Idade + 600. Têm Faculdade + 50.Têm Linkedin\n\nInterprete o efeito da Idade na variável salário. Que acontece com as pessoas que não tem faculdade? Considere agora que o desvio padrão do coeficiente da variável \"Têm Linkedin\" é de 47, por tanto o seu p-valor é \\~0.92 (como visto na equação abaixo). O que isso implica para o modelo em questão? Essa variável é relevante?\n\n::: callout-tip\n# Resposta\n:::\n:::\n",
    "supporting": [
      "Relatório_GAZEUS_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}